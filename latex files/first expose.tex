Deep Learning approach for non-goal driven conversation

OVERVIEW OF WORK:
Common chitchat models include lack of specificity, not displaying a consistent personality and not being very captivating to the user

Current approaches to chit-chat models are moving in the direction of making the model more engaging to the user by including profile information which gives the model a more human-like dialogue response.

Memory Augmentation in end-to-end models have been used to include this information in order for this to be 


PROBLEMS:

1. Database:
Chitchat models have been traditionally trained using datasets with many dialogues with different speakers such as Twitter, Reddit or OpenSubtitles corpa which leads to a lack of consistent personality in the model. These datasets contain a sequence of utterance and replies without any background knowledge of the speaker (or topic of discussion) associated with them.
This has resulted in development of models which treat conversation as a sequence-to-sequence generation task causing a simplistic response different to the way humans converse by relying on some background information.

In addition, these large-scale dataset are nosiy as they are extracted from online forums which are very noisy in terms of typographical errors, use of shorthand expression, etc.

For my work, I would be using the PERSONA-CHAT dataset which is a crowd-sourced dataset released by ParlAI. This dataset is collected using Amazon Mechanical Turk  where two Turkers are paired to converse on a particular topic and each Turker is provided a random profile from a pool of profiles on which they have to condition their dialogue.

On comparison of chitchat models built using the PERSONA-CHAT dataset against those built using the OpenSubtitles and Twitter dataset, these newly created dataset are less noisy as the Turkers have been instructed to use clean sentences. Human evaluations have shown the PERSONA CHAT dataset provide more engaging models that are capable of being consistent via conditioning on a profile.


2. Memory-Augmented Network:
Common chitchat models lack explicit long-term memory as they are typically trained to produce a reply based only on the recent dialogue history (Vinyals and Lee, 2015). 


The profile (persona) given to each speaker is stored in a memory-augmented neural network and then used during the training to produce a more personal, specific, consistent and engaging response. 


3. Tendency of model to produce consensual and generic responses (e.g I don't know) which are vague and non-engaging to humans





Due to these problems, chitchat models are usually not considered as an end-application





BREAKDOWN ON MODELS AVAILABLE FOR DATA-DRIVEN CONVERSATION MODELS

There are usually two types of models used in conversational models:
1. Ranking model: 
	This method produces a next utterance by considering any utterance in the training set as a possible candidate reply

2. Generative model: 
	This model generated new sentences by conditioning on the dialogue history (and possibly the persona information provided)



Paper on Generative models:

Chapter 5: Fully Data-Driven Conversation Models and Social Bots

- End-to-End Conversation Models:
1. LSTM model
2. HRED / VHRED model
3. Attention models
4. Pointer-Network models (copy and paste response)


- Grounded Conversation Models:
	Using Memory-Augmented network to encode facts from the dataset

- Unsupervised learning:
	Deep Reinforcement Learning


Various usage of these models can be found in the papers described below


RELATED WORK:

PAPER 1:
Personalizing Dialogue Agents: I have a dog, do you have pets too?

Overview:

Dataset: 
The PERSONA-CHAT dataset method was used in this paper where an Original Persona and a Revised Persona were both created

Models:
Next Utterance Prediction:
Two classes of models are considered in this paper for predicting the response:

1. Ranking model: This method produces a next utterance by considering any utterance in the training set as a possible candidate reply
2. Generative model: This model generated new sentences by conditioning on the dialogue history (and possibly the persona information provided)

Ranking models:
	- Baseline ranking models: - IR baseline model
							   - Supervised embedding model (Starspace)
		In these models, the profile information is incorporated by simply concatenating it to the query bag of words.
	- Ranking Profile Memory Network: uses both memory network and dialogue history as input and produces the next utterance by performing attention over the profile to find relevant lines to combine with the input
	
	- Key-Value Profile Memory Network: This method performs attention over keys and outputs the values as the reply (unlike the Profile Memory Network which outputs the keys itself as the reply). In the model, the dialogue history (from training set) is considered as the keys, and the dialogue utterances (replies from the speaking partner) as the values. This allows model have a memory of past dialogues to help influence its prediction.

Generative models:
	- Seq2Seq: input sequence encoded using LSTM where the final hidden state is fed into the decoder LSTM. For each time step, the decoder then produces the probability of the next word via softmax. The basic model is extended to include the profile information where it is simply prepended (concatenated) to the input sequence
	
	- Generative Profile Memory Network: each profile is encoded as an individual memory representation in a memory network. Again, dialogue history encoded using LSTM and its final state is used as the initial hidden state of the decoder. (Ẃithout the profile information addition, meaning no memory, this model would just be the Seq2Seq model)



PAPER 2:
Towards Exploiting Background Knowledge for Building Conversation Systems

Overview:
There have been work done on trying to integrate external knowledge sources with existing datasets (Rojas-Barahona et al 2017, Williams et al, 2016...), but building datasets where the utterances are explicitly linked to external background knowledge will improve the conversational models

Dataset:
The PERSONA-CHAT database style was used to create a new dataset using movie information such as movie plot, reviews, comments and facts. In this dataset, for every even numbered utterance, the speaker has to construct a sentence using the given information.

Size: About 9,000 conversations were collected with a total of 90,000 utterances (approx. 10 utterances per conversation) for a total of 921 different movies

Models:
1. Hierarchical Recurrent Encoder-Decoder (HRED): the model used is a hierarchical variant of the sequence to sequence architecture and it doesn't exploit any background information (such as the movie plot, reviews, etc.)
2. Copy-and-Generate model: the model tries to copy text as the reply from the given resources when appropriate and otherwise generates a new one-
3. Span prediction based model: Model popular for Question Answering works


- 	Generation based model:
	HRED is a generation based model which decomposes the context of the conversation as two level hierarchy using Recurrent Neural Networks (RNN). The lower level RNN encodes individual utterances (sequence of words) which is fed into the higher level RNN as a sequence of utterances. The decoder RNN then generates an output based on this hierarchical context representation.

- Generate-or-Copy model:
	Get To The Point (GTTP) (See et al., 2017). This proposes a hybrid pointer fenerator network that learns to copy words form the source document when required and otherwise generate new word like any sequence-to-sequence model.
	The input is a {document, context} pair concatenation where the document represents the merging of all background information such as facts, reviews, etc. and the context includes the two previous utterances and the current utterance, the output would be the response (which is labeled by the next utterance)
	
- Span prediction method:
	Bi-directional Attention Flow Model (BiDAF) is a Question Answering model. The model uses a six-layered architecture to predict the span in the document which contains the answer.
	
	Limitation:  For the BiDAF model, they had to restrict the length of the resources to 256 words because even on a 12GB RAM GPU, there was memory error created for longer documents
	
Evaluation:

1. HRED and GTTP models: BLEU-4, ROUGE-1, ROUGE-2 and ROUGE-L
2. BiDAF: The above metrics were used by comparing the predicted span with the reference span, also F1 metrics was used
3. Human evaluation on
	- fluency
	- appropriateness / relevance of response 
	- humanness of response
	- specificity of response (movie specific response)



PAPER 3:
TransferTransfo: A Transfer Learning Approach for Neural Network Based Conversational Agents

Overview:
This is a generative data-driven dialogue system using transfer learning based approach where a large database of words is first trained and the result is combined with a transformer (generative seq2seq) model.


Dataset:
The PERSONA-CHAT database style was used to create a new dataset using movie information such as movie plot, reviews, comments and facts. In this dataset, for every even numbered utterance, the speaker has to construct a sentence using the given information.

Size: About 9,000 conversations were collected with a total of 90,000 utterances (approx. 10 utterances per conversation) for a total of 921 different movies

Models:


Limitation:  

Evaluation:
-  The PERSON-CHAT dataset comes with 3 automated metrics on its evaluation seet:
	1. Language modeling task: where the metric is the perplexity of gold utterance tokens
	2. Next utterance retrieval task: where the metric is the accuracy of retrieving the best next utterance among 19 randomly sampled distractor responses sampled from other responses.
	3. Generation task: which consists in generating a response in the dialogue system and where the metric is the F1 (precision and recall) of the content words of the response utterance
	4. Human evaluation based on:
		- Fluency
		- Consistency
		- Engagingess
		- Guessing correct persona



	
	
	
	
	

EVALUATION:
1. Human Evaluation Measures:
	- Fluency
	- Engagingness
	- Consistency
	- Profile Detection (maybe)

2. Test done on PERSONA-CHAT hidden evaluation database

	
MY WORK:
1. MODEL APPROACHES
	e.g: implementing the transferto method suing memory augmented network
	
2. DATASET
There are two options on which dataset to use:
- Use of publicly available PERSONA-CHAT dataset created for the Conversational Intelligence Challenge which comes with 3 automated metrics on its evaluation set.
	There is also a privately held portion fo PERSONA-CHAT used for further evaluation

- Use of newly created dataset on movie (maybe describe how dataset is collected)


	
3. OTHER ADDITIONS TO PROVIDE IMPROVED REPLIES:
- Preventing the model to repeat the sentence from the profile word-for-word as a response

- Using the currently created Database: 
A database is being created using the Amazon Mechanical Turk, where more labels are being added to the conversation in order to improve the quality of the chitchat model response. Such labels include: Facts, ...







Thesis Expose

TO DO:

- Persona dataset - refer to paper (describe what the dataset is)
- Conv.ai - describe challenge, put link
- check best result and how they achieved them (papers)


- Look at baseline models from different papers for conversational models
- check dataset and content 

- Look into seq2seq and Key-Value Profile Memory (Good enough for Prof. for now)


Check TransferTransfo paper
1. Maybe: Combine Transfer learning method used here with KV Profile Memory network
- Not sure but I think in the paper they only used a generative model, not a ranking model
- Maybe pretraining on a dataset would improve the way KV attention model gets its output
- Check if memory augmentation was incorporated in the paper if not, this would be good start

2. Find better way to use Key-Value Memory:
- Think in paper, they have used sentence embedding, so try using word embedding or combining this with HRED method or something

3. Try to make the KV model a Generative model or try to improve it:
-e.g. Make a model that uses KV model to first outputs a value and use this output as an input to a generative model...


Others:
- Memory Augmented Neural Networks

Challenges:
- How to get the additional info from the newly created database into the network


If using Fabian's db:
- Check if better/more labeling improves result

- How does KV Prof. Memory perform if in addition to the input sentences, there are additionally attitudes linked to the input








---------------------------------------------------------------------------------------------------------------------------------------------------------------------------











Medical aspect of thesis:

Memory Augmented Conversational Agent with end use for cases of Depression

Wikipedia:

MDD, Depression is a mental disorder characterized by at least two weeks of low mood that is present across most situations.[1] It is often accompanied by low self-esteem, loss of interest in normally enjoyable activities, low energy, and pain without a clear cause. Major depressive disorder can negatively affect a person's personal life, work life, or education, as well as sleeping, eating habits, and general health.[1][3] Between 2–8% of adults with major depression die by suicide,[2][6] and about 50% of people who die by suicide had depression or another mood disorder.[7]

Major depressive disorder affected approximately 216 million people (3% of the world's population) in 2015.[5] The percentage of people who are affected at one point in their life varies from 7% in Japan to 21% in France.[4] Lifetime rates are higher in the developed world (15%) compared to the developing world (11%).[4]

A person having a major depressive episode usually exhibits a very low mood, which pervades all aspects of life, and an inability to experience pleasure in activities that were formerly enjoyed. Depressed people may be preoccupied with, or ruminate over, thoughts and feelings of worthlessness, inappropriate guilt or regret, helplessness, hopelessness, and self-hatred.[22] Other symptoms of depression include poor concentration and memory (especially in those with melancholic or psychotic features),[24] withdrawal from social situations and activities...

The three most common treatments for depression are psychotherapy, medication, and electroconvulsive therapy. Psychotherapy is the treatment of choice (over medication) for people under 18.

Several variables predict success for cognitive behavioral therapy in adolescents: higher levels of rational thoughts, less hopelessness, fewer negative thoughts, and fewer cognitive distortions.[164] CBT is particularly beneficial in preventing relapse.[165][166]



Article: 
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5478797/


Overcoming problems of stigma has been traditionally considered a major benefit of Internet-delivered and more recently mobile mental health interventions. In recent years, there has been an explosion of interest and development of such services to either supplement existing mental health treatments or expand limited access to quality mental health services [4]. This development is matched by great patient demand with about 70% showing interest in using mobile apps to self-monitor and self-manage their mental health [5]. 
Internet interventions for anxiety and depression have empirical support [6] with outcomes comparable to therapist-delivered cognitive behavioral therapy (CBT) [7,8]. Yet, despite demonstrated efficacy, they are characterized by relatively poor adoption and adherence. One review found a median minimal completion rate of 56% [9]. A hypothesized reason for this lack of adherence is the loss of the human interactional quality that in-person CBT retains. For example, certain therapeutic process factors such as accountability may be more salient in traditional face-to-face treatments, compared to digital health interventions.


https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4996669/

Depression, suicide, rape, and domestic violence are widespread but underrecognized public health issues. Barriers such as stigma, confidentiality, and fear of retaliation contribute to low rates of reporting

How the conversational agent responds is critical, because data show that the conversational style of software can influence behavior.4,5 

Importantly, empathy matters—callers to a suicide hotlines are 5 times more likely to hang up if the helper was independently rated as less empathetic.6

People with mental health concerns often prefer to seek support online rather than in person.9 In 2013, there were more than 42 million Web searches related to self-injury.10 Future research might determine the proportion of people using conversational agents to obtain information about various health issues, and how the use of these agents varies by age, sex, race, and ethnicity. 

A pressing challenge for mental health services is meeting the demand for the treatment of depression and anxiety disorders. Nearly 40% of the population is estimated to be in need of treatment at some time during their life for anxiety or depression [1]. Each year 14–18% of the population across the age span suffer an anxiety disorder and 7–9% suffer from depression in the United States as well as in Europe [1], [2]. Thus, meeting the needs of people suffering anxiety and depression with the current delivery methods is a gargantuan task [3]–[5].

Only one third of depressed patients respond fully to pharmacotherapy [6] and patients prefer psychological to pharmacologic treatment for depression and anxiety at a 3∶1 rate [7].


https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD009125.pub2/epdf/standard

In these training programs caregivers are encouraged to identifypleasant activities for patients, which encourage positive interac-tions and increase the involvement of physical and social activity Teri 2003.

Although most current clinical practice guidelines (Salzman 2008)recommend the use of non-pharmacological interventions as thefirst line of approach in treating both anxiety and depressionindementia (Hogan 2008), 

Behavioural strategies included participating in pleasantactivities thereby increasing success.

Spector 2012evaluated a CBT intervention for people with anxi-ety and dementia (10 sessions in total). The intervention includedidentifying and practicing strategies for feeling safe, challengingnegative thoughts, and incorporating calming thoughts and be-havioural experiments with the use of cue cards.


https://www.researchgate.net/publication/288445195_The_effect_of_reminiscence_therapy_on_the_elderly_with_dementia_-_Meta_analysis

This study aims to examine the effect of reminiscence therapy on the elderly with dementia. Two researchers collected the data of 375 cases in the randomized controlled trials(RCT) with the experimental group and control group involved, among which, 10 cases were chosen for this study. Among the dependant variables of the study, the effects on such factors as cognitive function, depression, behavior problem, and quality of life were analyzed, and it turned out that 'great effect' was shown when the cognitive function was 1.448(p=.004), depression-1.336(p=.002), and quality of life 1.308(p=.001) respectively. The significant effect was proved empirically as well (p<.05). In contrast, the effect on behavior problems was 0.322(p=.065), relatively small, and thus no significant effect was proved in this respect. It has been verified through this meta-analysis that reminiscence therapy is effective for the elderly with dementia.



Mine:

Aim: Making a social conversational agent for people with depression focusing on 

https://www.tandfonline.com/doi/full/10.1080/13607860701529932?scroll=top&needAccess=true

- old people homes: where there are lonely people with no one to talk to. People there would love to talk about their family, children, grandchildren
- young people: 

This project is aimed at improving a conversational agent with a persona which has the ability of holding a long term conversation using memory networks. As a forproject, this thesis would aim at using Movie dialogue dataset but for further work, this could be expanded to include all topics of life.
Movie dataset has been chosen as it is a common conversational topic of interest among people.

What this project is:
An exploration of different neural network architectures into producing a better performing conversational agent which could in the long run and with the right dataset when available, have the use of performing CBT by holding a conversation with an MDD patient in order to alleviate their mood (psychotherapy)

What this project is not:
A study on depression and how to treat it using conversation based psychotherapy.
Due to the unavalability of a conversational corpus with people with depression and also the ethical process involved in making one, this project would not focus on experimentation on such database but instead would look into the possibility of future uses.


Future inclusion to the project:
inclusion of functionality to call a Lifeline phone number if conversation seems like it is needed: e.g in case where user says "I feel like committing suicide".




